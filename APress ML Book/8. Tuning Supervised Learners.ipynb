{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Supervised Learners\n",
    "\n",
    "#### Measures of Performance\n",
    "##### Confusion matrix\n",
    "Visualises the performance of a classification algorithm. Rows represent the items belonging to the actual classes, column represents the items belonging to the predicted classes.\n",
    "\n",
    "Samples are categorised by being True/False Negatives/Positives (TN, FN, TP, FP). False positives are usually called a type 1 error, false negatives a type 2 error. There's usually a trade-off between the two, and which error you should be more concerned aout depends on the problem you're trying to solve.\n",
    "\n",
    "##### Recall\n",
    "A measure that indicates the ratio of positive test data items that are correctly identified out of all the items that are actually positive. Can be computed from the confusion matrix as $$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "##### Precision\n",
    "Measure that indicates ratio of the number of correctly predicted positive points to the number of all the points that were predicted as positive. $$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
